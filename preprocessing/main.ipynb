{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6ae2d8",
   "metadata": {
    "executionInfo": {
     "elapsed": 8111,
     "status": "ok",
     "timestamp": 1762852220689,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "af6ae2d8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Image = np.ndarray\n",
    "CharacterWithLabel = tuple[Image, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e215cd1",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1762852246871,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "1e215cd1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rRMw6Lm2DdZn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35503,
     "status": "ok",
     "timestamp": 1762852283782,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "rRMw6Lm2DdZn",
    "outputId": "aa3df720-076d-40cc-9e54-3e2e9536dfbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f473cda",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762852315656,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "1f473cda"
   },
   "outputs": [],
   "source": [
    "SOURCE_DIR = '/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled'\n",
    "BLACK_LINES_REMOVED_DIR = '/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/black_lines_removed'\n",
    "BLACK_LINES_REMOVED_SUFFIX = '_cleaned'\n",
    "CONTRAST_ENHANCED_DIR = '/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/contrast_enhanced'\n",
    "THICKNESS_ENHANCED_DIR = '/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/thickness_enhanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a95cdb",
   "metadata": {
    "id": "a2a95cdb"
   },
   "source": [
    "## 1.0 Remove Black Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef4254",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762852328316,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "1eef4254"
   },
   "outputs": [],
   "source": [
    "def remove_black_lines(img_path, save=True, output_dir=BLACK_LINES_REMOVED_DIR, suffix=BLACK_LINES_REMOVED_SUFFIX) -> Image:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read {img_path}\")\n",
    "        return None\n",
    "\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([8, 8, 8])\n",
    "    mask = cv2.inRange(img, lower_black, upper_black)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    cleaned = cv2.inpaint(img, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "    if save:\n",
    "        fname = os.path.basename(img_path)\n",
    "        name, ext = os.path.splitext(fname)\n",
    "        save_path = os.path.join(output_dir, f\"{name}{suffix}{ext}\")\n",
    "        cv2.imwrite(save_path, cleaned)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def remove_black_lines_from_dir(input_dir: str = SOURCE_DIR) -> List[Image]:\n",
    "  os.makedirs(BLACK_LINES_REMOVED_DIR, exist_ok=True)\n",
    "  cleaned_images = []\n",
    "  for image_path in glob.glob(os.path.join(input_dir, \"*.png\")):\n",
    "    print(image_path)\n",
    "    cleaned = remove_black_lines(image_path)\n",
    "    print(cleaned.shape)\n",
    "    cleaned_images.append(cleaned)\n",
    "  return cleaned_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004d151",
   "metadata": {
    "id": "d004d151"
   },
   "source": [
    "## 2.0 Contrast Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abee1a5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762852331371,
     "user": {
      "displayName": "Hannah Park",
      "userId": "05538127724277630611"
     },
     "user_tz": -480
    },
    "id": "4abee1a5"
   },
   "outputs": [],
   "source": [
    "def enhance_contrast_ycrcb(img_path, output_dir, save=True):\n",
    "    \"\"\"Enhance image contrast using histogram equalization on Y (luminance) channel.\"\"\"\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read {img_path}\")\n",
    "        return None\n",
    "\n",
    "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "\n",
    "    y_eq = cv2.equalizeHist(y)\n",
    "\n",
    "    ycrcb_eq = cv2.merge((y_eq, cr, cb))\n",
    "    enhanced = cv2.cvtColor(ycrcb_eq, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "    if save:\n",
    "        # os.makedirs(output_dir, exist_ok=True)\n",
    "        fname = os.path.basename(img_path)\n",
    "        name, ext = os.path.splitext(fname)\n",
    "        save_path = os.path.join(output_dir, f\"{name}_enhanced{ext}\")\n",
    "        cv2.imwrite(save_path, enhanced)\n",
    "        print(f\"✅ Saved enhanced image to: {save_path}\")\n",
    "\n",
    "    return img, enhanced\n",
    "\n",
    "\n",
    "def enhance_contrast_dir_input(input_dir = BLACK_LINES_REMOVED_DIR, output_dir = CONTRAST_ENHANCED_DIR, save=True):\n",
    "  if save:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for image_path in glob.glob(os.path.join(input_dir, \"*.png\")):\n",
    "    enhance_contrast_ycrcb(image_path, output_dir, save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243239c",
   "metadata": {
    "id": "c243239c"
   },
   "source": [
    "## Segment into characters by colour clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a5388",
   "metadata": {
    "id": "c66a5388"
   },
   "outputs": [],
   "source": [
    "def merge_duplicates(char_info, iou_threshold=0.6):\n",
    "    merged = []\n",
    "    used = [False] * len(char_info)\n",
    "\n",
    "    for i, info_i in enumerate(char_info):\n",
    "        if used[i]:\n",
    "            continue\n",
    "\n",
    "        x1_i, y1_i, x2_i, y2_i = info_i['bbox']\n",
    "        area_i = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "        merged_info = info_i\n",
    "\n",
    "        for j, info_j in enumerate(char_info):\n",
    "            if i == j or used[j]:\n",
    "                continue\n",
    "            x1_j, y1_j, x2_j, y2_j = info_j['bbox']\n",
    "            area_j = (x2_j - x1_j) * (y2_j - y1_j)\n",
    "\n",
    "            # intersection\n",
    "            inter_x1, inter_y1 = max(x1_i, x1_j), max(y1_i, y1_j)\n",
    "            inter_x2, inter_y2 = min(x2_i, x2_j), min(y2_i, y2_j)\n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "\n",
    "            iou = inter_area / float(area_i + area_j - inter_area + 1e-5)\n",
    "            if iou > iou_threshold:\n",
    "                used[j] = True  # mark duplicate as used\n",
    "\n",
    "        used[i] = True\n",
    "        merged.append(merged_info)\n",
    "\n",
    "    return merged\n",
    "\n",
    "def split_overlap(mask):\n",
    "    \"\"\"Try vertical projection first, else fallback to watershed.\"\"\"\n",
    "    proj = np.sum(mask, axis=0)\n",
    "    proj_smooth = cv2.GaussianBlur(proj, (7, 1), 0)\n",
    "\n",
    "    valleys = np.where(proj_smooth < 0.3 * np.max(proj_smooth))[0]\n",
    "    if len(valleys) > 0:\n",
    "        split = valleys[len(valleys) // 2]\n",
    "        return [mask[:, :split], mask[:, split:]]\n",
    "\n",
    "    dist = cv2.distanceTransform(mask, cv2.DIST_L2, 5)\n",
    "    _, fg = cv2.threshold(dist, 0.5 * dist.max(), 255, 0)\n",
    "    fg = np.uint8(fg)\n",
    "    unknown = cv2.subtract(mask, fg)\n",
    "    _, markers = cv2.connectedComponents(fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    imgc = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(imgc, markers)\n",
    "    pieces = []\n",
    "    for i in np.unique(markers):\n",
    "        if i <= 1:\n",
    "            continue\n",
    "        pieces.append(np.uint8(markers == i) * 255)\n",
    "    return pieces\n",
    "\n",
    "def segment_characters_color_overlap(image: Image, labels_string: str) -> List[CharacterWithLabel]:\n",
    "    \"\"\"\n",
    "    Segment individual characters using color clustering + connected components,\n",
    "    with overlap splitting and duplicate cleanup.\n",
    "    Returns a list of (cropped_character_image, label) pairs.\n",
    "    \"\"\"\n",
    "    if len(image.shape) != 3:\n",
    "        raise ValueError(\"Expected a color image (BGR).\")\n",
    "\n",
    "    k = len(labels_string)\n",
    "\n",
    "    # K-means clustering in HSV space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    pixels = hsv.reshape(-1, 3).astype(np.float32)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "    _, lbls, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    segmap = lbls.reshape(image.shape[:2])\n",
    "    bg_color = np.median(hsv.reshape(-1, 3), axis=0)\n",
    "\n",
    "    char_info = []\n",
    "    all_widths, all_areas = [], []\n",
    "\n",
    "    # cluster statistics\n",
    "    for cid in np.unique(segmap):\n",
    "        cluster_color = centers[cid]\n",
    "        if np.linalg.norm(cluster_color - bg_color) < 25:\n",
    "            continue\n",
    "\n",
    "        mask = (segmap == cid).astype(np.uint8) * 255\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "        n, _, stats, _ = cv2.connectedComponentsWithStats(mask, 8)\n",
    "\n",
    "        for i in range(1, n):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area > 50 and w > 8 and h > 8:\n",
    "                all_widths.append(w)\n",
    "                all_areas.append(area)\n",
    "\n",
    "    if len(all_widths) == 0:\n",
    "        return []\n",
    "\n",
    "    median_w = np.median(all_widths)\n",
    "    median_area = np.median(all_areas)\n",
    "\n",
    "    # bounding boxes\n",
    "    for cid in np.unique(segmap):\n",
    "        cluster_color = centers[cid]\n",
    "        if np.linalg.norm(cluster_color - bg_color) < 25:\n",
    "            continue\n",
    "\n",
    "        mask = (segmap == cid).astype(np.uint8) * 255\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "        n, _, stats, _ = cv2.connectedComponentsWithStats(mask, 8)\n",
    "\n",
    "        for i in range(1, n):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area < 50 or w < 8 or h < 8:\n",
    "                continue\n",
    "\n",
    "            # overlapping blobs\n",
    "            if w > 1.6 * median_w or area > 1.6 * median_area:\n",
    "                submasks = split_overlap(mask[y:y+h, x:x+w])\n",
    "            else:\n",
    "                submasks = [mask[y:y+h, x:x+w]]\n",
    "\n",
    "            for sm in submasks:\n",
    "                coords = np.where(sm > 0)\n",
    "                if len(coords[0]) == 0:\n",
    "                    continue  # Skip empty submasks\n",
    "\n",
    "                sm_y_min, sm_x_min = coords[0].min(), coords[1].min()\n",
    "                sm_y_max, sm_x_max = coords[0].max() + 1, coords[1].max() + 1\n",
    "\n",
    "                bbox_x1 = x + sm_x_min\n",
    "                bbox_y1 = y + sm_y_min\n",
    "                bbox_x2 = x + sm_x_max\n",
    "                bbox_y2 = y + sm_y_max\n",
    "\n",
    "                char_info.append({\n",
    "                    \"bbox\": (bbox_x1, bbox_y1, bbox_x2, bbox_y2),\n",
    "                    \"mask\": sm,\n",
    "                    \"cluster\": int(cid)\n",
    "                })\n",
    "\n",
    "    # merge duplicates and sort left-to-right\n",
    "    char_info = merge_duplicates(char_info)\n",
    "    char_info.sort(key=lambda ci: ci[\"bbox\"][0])\n",
    "\n",
    "    if len(char_info) > len(labels_string):\n",
    "        char_info = char_info[:len(labels_string)]\n",
    "    elif len(char_info) < len(labels_string):\n",
    "        labels_string = labels_string[:len(char_info)]\n",
    "\n",
    "    labeled_characters: List[CharacterWithLabel] = []\n",
    "    for info, label in zip(char_info, labels_string):\n",
    "        x1, y1, x2, y2 = info[\"bbox\"]\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "        labeled_characters.append((cropped, label))\n",
    "\n",
    "    return labeled_characters\n",
    "\n",
    "\n",
    "def segment_into_characters(image_dir: str = CONTRAST_ENHANCED_DIR) -> List[CharacterWithLabel]:\n",
    "  segmented_character_with_labels: List[CharacterWithLabel] = []\n",
    "  for filename in os.listdir(image_dir):\n",
    "    print(filename)\n",
    "    if not filename.endswith(\".png\"):\n",
    "      continue\n",
    "    print(\"passed\")\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    labels_string = name.split(\"-\")[0]\n",
    "    img = cv2.imread(os.path.join(image_dir, filename))\n",
    "    if img is None:\n",
    "      print(f\"⚠️ Could not read {os.path.join(image_dir, filename)}\")\n",
    "      continue\n",
    "    segmented = segment_characters_color_overlap(img, labels_string)\n",
    "    segmented_character_with_labels.extend(segmented)\n",
    "  return segmented_character_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186c5ae",
   "metadata": {
    "id": "9186c5ae"
   },
   "source": [
    "## 4.1 Transform thin characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ed3be",
   "metadata": {
    "id": "3c5ed3be"
   },
   "outputs": [],
   "source": [
    "def transform_resolve_thin_characters(characters: List[CharacterWithLabel], is_save: bool = True):\n",
    "  transformed = []\n",
    "  output_dir = THICKNESS_ENHANCED_DIR\n",
    "  if is_save:\n",
    "      os.makedirs(output_dir, exist_ok=True) # Create output directory once\n",
    "\n",
    "  for idx, (img, label) in enumerate(characters):\n",
    "    if img is None:\n",
    "      print(f\"Warning: Skipping invalid image for label '{label}'\")\n",
    "      continue\n",
    "\n",
    "    # --- Step 1: CLAHE on L channel (contrast enhancement) ---\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    enhanced = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # --- Step 2: Contrast stretching (deepens dark text without crushing highlights) ---\n",
    "    min_val, max_val = np.min(enhanced), np.max(enhanced)\n",
    "    stretched = cv2.convertScaleAbs(enhanced, alpha=255.0/(max_val - min_val), beta=-255.0*min_val/(max_val - min_val))\n",
    "\n",
    "    # --- Step 3: Slight sharpening to improve text edge clarity ---\n",
    "    blur = cv2.GaussianBlur(stretched, (0, 0), 1.2)\n",
    "    sharpened = cv2.addWeighted(stretched, 1.4, blur, -0.4, 0)\n",
    "\n",
    "    # --- Step 4: Subtle thickening (morphology only on dark regions) ---\n",
    "    gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask_dark = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    mask_dilated = cv2.dilate(mask_dark, kernel, iterations=1)\n",
    "    mask_dilated = cv2.GaussianBlur(mask_dilated, (3, 3), 0)\n",
    "    mask_dilated = mask_dilated.astype(float) / 255.0\n",
    "\n",
    "    # Blend thickened regions into sharpened image\n",
    "    thickened = sharpened.astype(float)\n",
    "    for c in range(3):\n",
    "        thickened[..., c] = thickened[..., c] * (1 - 0.15 * mask_dilated)  # darken dark strokes slightly\n",
    "\n",
    "    thickened = np.clip(thickened, 0, 255).astype(np.uint8)\n",
    "    transformed.append((thickened, label))\n",
    "\n",
    "    # Save result if needed\n",
    "    if is_save:\n",
    "        save_path = os.path.join(output_dir, f\"{idx:05d}_{label}.png\")\n",
    "        cv2.imwrite(save_path, thickened)\n",
    "        # print(f\"✅ Saved enhanced image to: {save_path}\")\n",
    "\n",
    "  return transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e13e57",
   "metadata": {
    "id": "37e13e57"
   },
   "source": [
    "## 4.2 Deskew characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd03ef",
   "metadata": {
    "id": "9ddd03ef"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------\n",
    "# PCA-based angle estimation (improved)\n",
    "# ---------------------------------------------------------------\n",
    "def estimate_angle_pca(mask: Image) -> float:\n",
    "    \"\"\"Estimate skew angle using PCA on character pixels.\"\"\"\n",
    "    mask_binary = (mask > 0).astype(np.uint8)\n",
    "    # Invert if background is dark\n",
    "    if np.mean(mask_binary) > 127:\n",
    "        mask_binary = cv2.bitwise_not(mask_binary)\n",
    "\n",
    "    coords = np.column_stack(np.where(mask_binary > 0))\n",
    "    if len(coords) < 10:\n",
    "        return 0.0\n",
    "\n",
    "    mean, eigenvectors = cv2.PCACompute(coords.astype(np.float32), mean=None)\n",
    "    if eigenvectors is None or len(eigenvectors) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    v = eigenvectors[0]\n",
    "    angle = np.degrees(np.arctan2(v[1], v[0]))\n",
    "\n",
    "    # Normalize angle to [-45, 45] range\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    elif angle > 45:\n",
    "        angle -= 90\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Projection-based angle estimation (alternative method)\n",
    "# ---------------------------------------------------------------\n",
    "def estimate_angle_projection(mask: Image) -> float:\n",
    "    \"\"\"Estimate angle using horizontal projection profile variance.\"\"\"\n",
    "    mask_binary = (mask > 0).astype(np.uint8)\n",
    "    if np.mean(mask_binary) > 127:\n",
    "        mask_binary = cv2.bitwise_not(mask_binary)\n",
    "\n",
    "    h, w = mask_binary.shape\n",
    "    if h < 10 or w < 10:\n",
    "        return 0.0\n",
    "\n",
    "    best_angle = 0.0\n",
    "    max_variance = 0\n",
    "\n",
    "    # Coarse search first (every 5 degrees)\n",
    "    for angle in range(-30, 31, 5):\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(mask_binary, M, (w, h), borderValue=0)\n",
    "        projection = np.sum(rotated, axis=1)\n",
    "        variance = np.var(projection)\n",
    "\n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            best_angle = float(angle)\n",
    "\n",
    "    # Fine search around best angle (every 1 degree)\n",
    "    for angle in range(int(best_angle) - 4, int(best_angle) + 5, 1):\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(mask_binary, M, (w, h), borderValue=0)\n",
    "        projection = np.sum(rotated, axis=1)\n",
    "        variance = np.var(projection)\n",
    "\n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            best_angle = float(angle)\n",
    "\n",
    "    return best_angle\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Improved deskew decision logic\n",
    "# ---------------------------------------------------------------\n",
    "def should_deskew(mask: Image, angle_threshold: float = 2.0, debug: bool = False) -> Tuple[bool, float]:\n",
    "    \"\"\"Determine if character should be deskewed.\"\"\"\n",
    "    angle_pca = estimate_angle_pca(mask)\n",
    "\n",
    "    # If PCA gives unreliable result (0 or very small), try projection method\n",
    "    if abs(angle_pca) < 1.0:\n",
    "        angle_proj = estimate_angle_projection(mask)\n",
    "        if abs(angle_proj) > 1.0:\n",
    "            angle = angle_proj\n",
    "        else:\n",
    "            angle = angle_pca\n",
    "    else:\n",
    "        angle = angle_pca\n",
    "\n",
    "    if debug:\n",
    "        print(f\"  Detected angle: {angle:.1f}°\")\n",
    "\n",
    "    # More lenient threshold - deskew if angle > threshold degrees\n",
    "    if abs(angle) < angle_threshold:\n",
    "        if debug:\n",
    "            print(f\"  Decision: NO DESKEW (angle too small)\")\n",
    "        return False, angle\n",
    "\n",
    "    if debug:\n",
    "        print(f\"  Decision: DESKEW\")\n",
    "    return True, angle\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Apply rotation with proper border handling\n",
    "# ---------------------------------------------------------------\n",
    "def deskew_character(image: Image, mask: Image, debug: bool = False) -> Tuple[Image, float]:\n",
    "    \"\"\"Deskew a character image.\"\"\"\n",
    "    should_rotate, angle = should_deskew(mask, debug=debug)\n",
    "\n",
    "    if not should_rotate or abs(angle) < 1.0:\n",
    "        return image, 0.0\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Calculate rotation matrix\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)\n",
    "\n",
    "    # Calculate new dimensions to avoid clipping\n",
    "    cos = np.abs(rot_matrix[0, 0])\n",
    "    sin = np.abs(rot_matrix[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # Adjust rotation matrix for new center\n",
    "    rot_matrix[0, 2] += (new_w / 2) - center[0]\n",
    "    rot_matrix[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # Set border color based on image type\n",
    "    if len(image.shape) == 3:\n",
    "        border_color = (255, 255, 255)  # White for BGR\n",
    "    else:\n",
    "        border_color = 255  # White for grayscale\n",
    "\n",
    "    # Rotate with white background\n",
    "    rotated = cv2.warpAffine(image, rot_matrix, (new_w, new_h),\n",
    "                            flags=cv2.INTER_CUBIC, borderValue=border_color)\n",
    "\n",
    "    # Crop to remove white borders by finding bounding box of content\n",
    "    if len(rotated.shape) == 3:\n",
    "        gray = cv2.cvtColor(rotated, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = rotated\n",
    "\n",
    "    # Find non-white regions\n",
    "    _, binary = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "\n",
    "    if len(coords) > 0:\n",
    "        y_min, x_min = coords.min(axis=0)\n",
    "        y_max, x_max = coords.max(axis=0)\n",
    "\n",
    "        # Add small padding\n",
    "        padding = 2\n",
    "        y_min = max(0, y_min - padding)\n",
    "        x_min = max(0, x_min - padding)\n",
    "        y_max = min(rotated.shape[0], y_max + padding + 1)\n",
    "        x_max = min(rotated.shape[1], x_max + padding + 1)\n",
    "\n",
    "        rotated = rotated[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    return rotated, angle\n",
    "\n",
    "\n",
    "\n",
    "def deskew_characters(characters_with_labels: List[CharacterWithLabel], debug: bool = False, visualize: bool = False) -> List[CharacterWithLabel]:\n",
    "    deskewed: List[CharacterWithLabel] = []\n",
    "\n",
    "    for idx, (char_img, label) in enumerate(characters_with_labels):\n",
    "        gray = cv2.cvtColor(char_img, cv2.COLOR_BGR2GRAY) if len(char_img.shape) == 3 else char_img\n",
    "        _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"\\nCharacter {idx + 1} ('{label}'):\")\n",
    "\n",
    "        rotated, angle = deskew_character(char_img, mask, debug=debug)\n",
    "        deskewed.append((rotated, label))\n",
    "\n",
    "        if visualize:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "            axes[0].imshow(cv2.cvtColor(char_img, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(f\"Before '{label}'\")\n",
    "            axes[0].axis(\"off\")\n",
    "            axes[1].imshow(cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title(f\"After ({angle:.1f}°)\")\n",
    "            axes[1].axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return deskewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6v5ThmqkDFuz",
   "metadata": {
    "id": "6v5ThmqkDFuz"
   },
   "source": [
    "# 4.3 Smoothen edges, random rotate, random zoom, add gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awfvwmjYDPoP",
   "metadata": {
    "id": "awfvwmjYDPoP"
   },
   "outputs": [],
   "source": [
    "SMOOTHENED_DIR = \"/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/outputs/smoothed_characters\"\n",
    "ROTATED_DIR = \"/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/outputs/rotated_characters\"\n",
    "ZOOMED_DIR = \"/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/outputs/zoomed_characters\"\n",
    "NOISED_DIR = \"/content/drive/MyDrive/cs4243-project/preprocessing/clean/all_relabelled/outputs/noised_characters\"\n",
    "\n",
    "def transform_smoothen_edges(characters: List[CharacterWithLabel], is_save: bool = True):\n",
    "    transformed = []\n",
    "    output_dir = SMOOTHENED_DIR\n",
    "    if is_save:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, (img, label) in enumerate(characters):\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Warning: Skipping invalid image for label '{label}'\")\n",
    "            continue\n",
    "\n",
    "        # --- Step 1: Edge-preserving smoothing ---\n",
    "        # This keeps color edges sharp while smoothing inside regions\n",
    "        smoothed = cv2.edgePreservingFilter(img, flags=1, sigma_s=40, sigma_r=0.3)\n",
    "\n",
    "        # --- Step 2: Optional mild bilateral smoothing to further refine edges ---\n",
    "        smoothed = cv2.bilateralFilter(smoothed, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "\n",
    "        # --- Step 3: Optional gentle Gaussian blur to remove remaining roughness ---\n",
    "        smoothed = cv2.GaussianBlur(smoothed, (3, 3), 0.5)\n",
    "\n",
    "        transformed.append((smoothed, label))\n",
    "\n",
    "        # --- Step 4: Save result if needed ---\n",
    "        if is_save:\n",
    "            save_path = os.path.join(output_dir, f\"{idx:05d}_{label}.png\")\n",
    "            cv2.imwrite(save_path, smoothed)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "def transform_random_rotate(characters: List[CharacterWithLabel], is_save: bool = True):\n",
    "    transformed = []\n",
    "    output_dir = ROTATED_DIR\n",
    "    if is_save:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, (img, label) in enumerate(characters):\n",
    "        if img is None:\n",
    "            print(f\"Warning: Skipping invalid image for label '{label}'\")\n",
    "            continue\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # --- Step 1: Randomly choose a rotation angle between -20° and +20° ---\n",
    "        angle = random.uniform(-20, 20)\n",
    "\n",
    "        # --- Step 2: Compute rotation matrix around the image center ---\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "        # --- Step 3: Apply rotation using affine transform ---\n",
    "        # Use border mode to fill outside regions smoothly (instead of black)\n",
    "        rotated = cv2.warpAffine(\n",
    "            img,\n",
    "            M,\n",
    "            (w, h),\n",
    "            flags=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REPLICATE\n",
    "        )\n",
    "\n",
    "        transformed.append((rotated, label))\n",
    "\n",
    "        # --- Step 4: Save result if needed ---\n",
    "        if is_save:\n",
    "            save_path = os.path.join(output_dir, f\"{idx:05d}_{label}.png\")\n",
    "            cv2.imwrite(save_path, rotated)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "MAX_ZOOM_OUT_FACTOR = 0.8\n",
    "MAX_ZOOM_IN_FACTOR = 1.2\n",
    "def transform_random_zoom(characters: List[CharacterWithLabel], is_save: bool = True):\n",
    "    transformed = []\n",
    "    output_dir = ZOOMED_DIR\n",
    "    if is_save:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, (img, label) in enumerate(characters):\n",
    "        if img is None:\n",
    "            print(f\"Warning: Skipping invalid image for label '{label}'\")\n",
    "            continue\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # --- Step 1: Choose random zoom factor (e.g., between 0.9x and 1.1x) ---\n",
    "        zoom_factor = random.uniform(MAX_ZOOM_OUT_FACTOR, MAX_ZOOM_IN_FACTOR)\n",
    "\n",
    "        # --- Step 2: Compute new size after zoom ---\n",
    "        new_w, new_h = int(w * zoom_factor), int(h * zoom_factor)\n",
    "        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # --- Step 3: Crop or pad to restore original size ---\n",
    "        if zoom_factor < 1.0:\n",
    "            # Zoomed out → need to pad\n",
    "            pad_w = (w - new_w) // 2\n",
    "            pad_h = (h - new_h) // 2\n",
    "            zoomed = cv2.copyMakeBorder(\n",
    "                resized,\n",
    "                pad_h,\n",
    "                h - new_h - pad_h,\n",
    "                pad_w,\n",
    "                w - new_w - pad_w,\n",
    "                borderType=cv2.BORDER_REPLICATE\n",
    "            )\n",
    "        else:\n",
    "            # Zoomed in → need to crop\n",
    "            start_x = (new_w - w) // 2\n",
    "            start_y = (new_h - h) // 2\n",
    "            zoomed = resized[start_y:start_y + h, start_x:start_x + w]\n",
    "\n",
    "        transformed.append((zoomed, label))\n",
    "\n",
    "        # --- Step 4: Save result if needed ---\n",
    "        if is_save:\n",
    "            save_path = os.path.join(output_dir, f\"{idx:05d}_{label}.png\")\n",
    "            cv2.imwrite(save_path, zoomed)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "def transform_add_gaussian_noise(characters: List[CharacterWithLabel], is_save: bool = True):\n",
    "    transformed = []\n",
    "    output_dir = NOISED_DIR\n",
    "    if is_save:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, (img, label) in enumerate(characters):\n",
    "        if img is None:\n",
    "            print(f\"Warning: Skipping invalid image for label '{label}'\")\n",
    "            continue\n",
    "\n",
    "        # --- Step 1: Normalize image to float32 for noise addition ---\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "\n",
    "        # --- Step 2: Generate Gaussian noise ---\n",
    "        # mean = 0, stddev between 0.01 and 0.03 (light noise)\n",
    "        noise_std = random.uniform(0.01, 0.03)\n",
    "        noise = np.random.normal(0, noise_std, img_float.shape).astype(np.float32)\n",
    "\n",
    "        # --- Step 3: Add noise and clip back to valid range ---\n",
    "        noisy = np.clip(img_float + noise, 0.0, 1.0)\n",
    "\n",
    "        # --- Step 4: Convert back to uint8 ---\n",
    "        noisy_uint8 = (noisy * 255).astype(np.uint8)\n",
    "\n",
    "        transformed.append((noisy_uint8, label))\n",
    "\n",
    "        # --- Step 5: Save result if needed ---\n",
    "        if is_save:\n",
    "            save_path = os.path.join(output_dir, f\"{idx:05d}_{label}.png\")\n",
    "            cv2.imwrite(save_path, noisy_uint8)\n",
    "\n",
    "    return transformed\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9186c5ae",
    "37e13e57",
    "6v5ThmqkDFuz"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
